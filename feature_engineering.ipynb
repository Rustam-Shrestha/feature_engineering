{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a60b49",
   "metadata": {},
   "source": [
    "# Feature Engineering with Pandas\n",
    "\n",
    "This notebook covers various aspects of handling data in Pandas, including types of data, selecting data types, dealing with categorical variables, encoding, handling uncommon categories, numeric variables, binarizing, binning, and handling missing data.\n",
    "\n",
    "We will use real datasets:\n",
    "- Stack Overflow Developer Survey 2023: https://raw.githubusercontent.com/Stephen137/stack_overflow_developer_survey_2023/main/data/survey_results_public_2023.csv\n",
    "- NYC Restaurant Inspection Results: https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD\n",
    "\n",
    "Note: The Stack Overflow data has columns like 'Country', 'ConvertedCompYearly' (similar to ConvertedSalary), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8fab8",
   "metadata": {},
   "source": [
    "## Types of Data\n",
    "\n",
    "- Continuous data\n",
    "- Categorical (e.g., gender, birth country)\n",
    "- Ordinal: order without actual distance\n",
    "- Boolean\n",
    "- Date time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f8398",
   "metadata": {},
   "source": [
    "## Exercise 1: Loading Data and Checking Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae3f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      qid       qname                                           question  \\\n",
      "0    QID2  MainBranch  Which of the following options best describes ...   \n",
      "1  QID127         Age                                 What is your age?*   \n",
      "2  QID296  Employment  Which of the following best describes your cur...   \n",
      "3  QID308  RemoteWork  Which best describes your current work situation?   \n",
      "4  QID341       Check  Just checking to make sure you are paying atte...   \n",
      "\n",
      "  force_resp type selector  \n",
      "0       True   MC     SAVR  \n",
      "1       True   MC     SAVR  \n",
      "2       True   MC     MAVR  \n",
      "3      False   MC     SAVR  \n",
      "4       True   MC     SAVR  \n",
      "\n",
      "Column Data Types:\n",
      "qid           object\n",
      "qname         object\n",
      "question      object\n",
      "force_resp    object\n",
      "type          object\n",
      "selector      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the URL for Stack Overflow survey\n",
    "so_survey_csv = \"survey_results_schema.csv\"\n",
    "# Load the data\n",
    "so_survey_df = pd.read_csv(so_survey_csv)\n",
    "\n",
    "# Print the first five rows\n",
    "print(so_survey_df.head())\n",
    "\n",
    "# Print the data types\n",
    "print('\\nColumn Data Types:')\n",
    "print(so_survey_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1e192",
   "metadata": {},
   "source": [
    "## Selecting Specific Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2073f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create subset of only the numeric columns\n",
    "so_numeric_df = so_survey_df.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Print the column names\n",
    "print(so_numeric_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e3960",
   "metadata": {},
   "source": [
    "## Dealing with Categorical Variables\n",
    "\n",
    "We encode categorical variables into numbers or booleans.\n",
    "\n",
    "Types of encoding:\n",
    "1. One-Hot Encoding: n categories into n features.\n",
    "2. Dummy Encoding: n categories into n-1 features, omitting one to avoid collinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b01fbf",
   "metadata": {},
   "source": [
    "## One-Hot Encoding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286c3889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'OH_Germany', 'OH_India', 'OH_Nepal', 'OH_USA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace', 'Hannah', 'Ian', 'Jack',\n",
    "             'Kira', 'Liam', 'Mona', 'Nina', 'Oscar', 'Paul', 'Quinn', 'Rita', 'Sam', 'Tina'],\n",
    "    'Country': ['USA', 'India', 'USA', 'Germany', 'India', 'Nepal', 'Germany', 'USA', 'Nepal', 'India',\n",
    "                'Germany', 'USA', 'Nepal', 'India', 'USA', 'Germany', 'Nepal', 'India', 'USA', 'Nepal']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the dataset\n",
    "# print(df)\n",
    "\n",
    "\n",
    "# Convert the Country column to one-hot encoded DataFrame\n",
    "one_hot_encoded = pd.get_dummies(df, columns=['Country'], prefix='OH')\n",
    "\n",
    "# Print the column names\n",
    "print(one_hot_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd332cf7",
   "metadata": {},
   "source": [
    "## Dummy Encoding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afe4d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'DM_India', 'DM_Nepal', 'DM_USA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables for the Country column\n",
    "dummy = pd.get_dummies(df, columns=['Country'], drop_first=True, prefix='DM')\n",
    "\n",
    "# Print the column names\n",
    "print(dummy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a0335",
   "metadata": {},
   "source": [
    "## Dealing with Uncommon Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94edeafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "Other    20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a series out of the Country column\n",
    "countries = df['Country']\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Create a mask for categories that occur less than 10 times\n",
    "mask = countries.isin(country_counts[country_counts < 10].index)\n",
    "\n",
    "# Label all other categories as 'Other'\n",
    "df.loc[mask, 'Country'] = 'Other'\n",
    "\n",
    "# Print the updated category counts\n",
    "print(df['Country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a84efd",
   "metadata": {},
   "source": [
    "## Numeric Variables\n",
    "\n",
    "Example with Restaurant Data: Binarizing violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df58a91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CAMIS                  DBA       BORO BUILDING             STREET  \\\n",
      "0  50175073      KUCHELA KUIZINE   Brooklyn     1197    FLATBUSH AVENUE   \n",
      "1  50170738  787 COFFEE WEST LLC  Manhattan      245   WEST   46 STREET   \n",
      "2  50036660          KIKOO SUSHI  Manhattan      141           1 AVENUE   \n",
      "3  50172620           FRIJOLEROS   Brooklyn      131  GREENPOINT AVENUE   \n",
      "4  50171814     ACE SHAWARMA INC      Bronx     3455      JEROME AVENUE   \n",
      "\n",
      "   ZIPCODE       PHONE CUISINE DESCRIPTION INSPECTION DATE  \\\n",
      "0  11226.0  3473355072                 NaN      01/01/1900   \n",
      "1  10036.0  9082308846                 NaN      01/01/1900   \n",
      "2  10003.0  2125333888            Japanese      03/25/2024   \n",
      "3  11222.0  3473842957                 NaN      01/01/1900   \n",
      "4  10467.0  6467023905                 NaN      01/01/1900   \n",
      "\n",
      "                                            ACTION  ...  \\\n",
      "0                                              NaN  ...   \n",
      "1                                              NaN  ...   \n",
      "2  Violations were cited in the following area(s).  ...   \n",
      "3                                              NaN  ...   \n",
      "4                                              NaN  ...   \n",
      "\n",
      "                         INSPECTION TYPE   Latitude  Longitude  \\\n",
      "0                                    NaN  40.641133 -73.956249   \n",
      "1                                    NaN  40.759204 -73.986536   \n",
      "2  Cycle Inspection / Initial Inspection  40.727952 -73.985034   \n",
      "3                                    NaN  40.730126 -73.955025   \n",
      "4                                    NaN  40.881555 -73.882581   \n",
      "\n",
      "   Community Board Council District Census Tract        BIN           BBL  \\\n",
      "0            314.0             45.0      79000.0  3119633.0  3.051880e+09   \n",
      "1            105.0              3.0      12500.0  1024737.0  1.010180e+09   \n",
      "2            103.0              2.0       3800.0  1006381.0  1.004500e+09   \n",
      "3            301.0             33.0      56500.0  3064721.0  3.025580e+09   \n",
      "4            207.0             11.0      42100.0  2017713.0  2.033240e+09   \n",
      "\n",
      "    NTA  Location Point1  \n",
      "0  BK95              NaN  \n",
      "1  MN17              NaN  \n",
      "2  MN22              NaN  \n",
      "3  BK76              NaN  \n",
      "4  BX43              NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "   SCORE  has_violation\n",
      "0    NaN              0\n",
      "1    NaN              0\n",
      "2   36.0              1\n",
      "3    NaN              0\n",
      "4    NaN              0\n"
     ]
    }
   ],
   "source": [
    "# Load NYC Restaurant Inspection Data\n",
    "restaurant_csv = 'https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv?accessType=DOWNLOAD'\n",
    "restaurant_df = pd.read_csv(restaurant_csv)\n",
    "\n",
    "# Print head\n",
    "print(restaurant_df.head())\n",
    "\n",
    "# For simplicity, assume 'SCORE' represents violation score (higher score = more violations)\n",
    "# Create a binary column: has_violation if SCORE > 0\n",
    "restaurant_df['has_violation'] = 0\n",
    "restaurant_df.loc[restaurant_df['SCORE'] > 0, 'has_violation'] = 1\n",
    "\n",
    "# Print sample\n",
    "print(restaurant_df[['SCORE', 'has_violation']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1616e",
   "metadata": {},
   "source": [
    "## Binning Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a945f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to SO data for salary binning\n",
    "# Note: Column is 'ConvertedCompYearly'\n",
    "\n",
    "# Create Paid_Job column filled with zeros\n",
    "so_survey_df['Paid_Job'] = 0\n",
    "\n",
    "# Replace where ConvertedCompYearly > 0\n",
    "so_survey_df.loc[so_survey_df['ConvertedCompYearly'] > 0, 'Paid_Job'] = 1\n",
    "\n",
    "# Print sample\n",
    "print(so_survey_df[['Paid_Job', 'ConvertedCompYearly']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101704c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Specify bin boundaries\n",
    "bins = [-np.inf, 10000, 50000, 100000, 150000, np.inf]\n",
    "\n",
    "# Bin labels\n",
    "labels = ['Very low', 'Low', 'Medium', 'High', 'Very high']\n",
    "\n",
    "# Bin the ConvertedCompYearly\n",
    "so_survey_df['boundary_binned'] = pd.cut(so_survey_df['ConvertedCompYearly'], bins=bins, labels=labels)\n",
    "\n",
    "# Print sample\n",
    "print(so_survey_df[['boundary_binned', 'ConvertedCompYearly']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb44617",
   "metadata": {},
   "source": [
    "## Handling Gaps in Data (Missing Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f652d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check info\n",
    "so_survey_df.info()\n",
    "\n",
    "# Check missing values\n",
    "print(so_survey_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For restaurant data\n",
    "restaurant_df.info()\n",
    "\n",
    "print(restaurant_df.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
